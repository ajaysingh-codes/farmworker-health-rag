{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ADTRu2VUFzc_"
      ],
      "authorship_tag": "ABX9TyOO36ALGIgUxj99YfnoamDh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaysingh-codes/farmworker-health-rag/blob/main/farmworker_health_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Farmworker Health Research RAG System\n",
        "\n",
        "**A smart search system for scientific literature on farmworker health, chemical exposures, and occupational stressors**\n",
        "\n",
        "Built with BM25 + Semantic Search | Interactive comparison interface | Optimized for health research papers\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QWo30qxeFUHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Installing Required Libraries\n",
        "This cell installs all the necessary Python packages for our RAG system:\n",
        "- `sentence-transformers`: For creating semantic embeddings of text\n",
        "- `bm25s`: For keyword-based search (BM25 algorithm)\n",
        "- `pypdf2`: For extracting text from PDF files\n",
        "- `pandas`: For data manipulation\n",
        "- `numpy`: For numerical operations\n",
        "- `joblib`: For saving/loading embeddings\n",
        "- `ipywidgets`: For creating the interactive interface"
      ],
      "metadata": {
        "id": "ADTRu2VUFzc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers bm25s pypdf2 pandas numpy joblib ipywidgets -q\n",
        "print(\"Libraries installed successfully\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SMbo3Du8FW-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries and Creating Workspace\n",
        "This cell:\n",
        "1. Imports all the libraries we'll use throughout the project\n",
        "2. Creates a dedicated folder `/content/papers` for your PDF files\n",
        "3. Sets up the basic environment for our RAG system"
      ],
      "metadata": {
        "id": "0adljKo_H2ZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKwRGdlH4XBF"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import bm25s\n",
        "import joblib\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from IPython.display import display, Markdown\n",
        "import ipywidgets as widgets\n",
        "from PyPDF2 import PdfReader\n",
        "from datetime import datetime\n",
        "\n",
        "# Create a folder for your PDFs\n",
        "pdf_folder = \"/content/papers\"\n",
        "if not os.path.exists(pdf_folder):\n",
        "    os.makedirs(pdf_folder)\n",
        "    print(f\"‚úÖ Created folder: {pdf_folder}\")\n",
        "else:\n",
        "    print(f\"üìÅ Folder already exists: {pdf_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Your Research Papers\n",
        "Upload your 5 PDF papers about farmworker health:\n",
        "- Click 'Choose Files' to select your PDFs\n",
        "- Papers will be moved to the `papers` folder\n",
        "- You'll see confirmation for each uploaded file"
      ],
      "metadata": {
        "id": "LyjiJSd2JV8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Click 'Choose Files' below to upload your 5 PDFs:\\n\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded files to the papers folder\n",
        "for filename in uploaded.keys():\n",
        "    destination = os.path.join(pdf_folder, filename)\n",
        "    os.rename(filename, destination)\n",
        "    print(f\"‚úÖ Uploaded: {filename}\")\n",
        "\n",
        "# Verify and list all PDFs in the folder\n",
        "pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith('.pdf')]\n",
        "print(f\"üìä Total PDFs in folder: {len(pdf_files)}\")\n",
        "for i, pdf in enumerate(pdf_files, 1):\n",
        "    print(f\"  {i}. {pdf}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7hlh6-xJJVg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking Function with Overlap\n",
        "Using 150-word chunks with 20% overlap for optimal context"
      ],
      "metadata": {
        "id": "IcndPkDoVWeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import re\n",
        "\n",
        "def get_chunks_fixed_size_with_overlap(text: str, chunk_size: int, overlap_fraction: float) -> List[str]:\n",
        "  \"\"\"\n",
        "  Splits text into fixed-size chunks with overlap.\n",
        "\n",
        "  Parameters:\n",
        "  - text (str): The text to be split into chunks.\n",
        "  - chunk_size (int): The desired size of each chunk.\n",
        "  - overlap_fraction (float): The fraction of overlap between chunks (0.2 = 20% overlap)\n",
        "\n",
        "  Returns:\n",
        "  - List[str]: A list of text chunks where each chunk might overlap with its adjacent chunk.\n",
        "\n",
        "  \"\"\"\n",
        "  # Split text into individual words\n",
        "  text_words = text.split()\n",
        "\n",
        "  # Calculate the number of words to overlap\n",
        "  overlap_int = int(chunk_size * overlap_fraction)\n",
        "\n",
        "  #Initialize a list to store resulting chunks\n",
        "  chunks = []\n",
        "\n",
        "  # Create chunks with overlap\n",
        "  for i in range(0, len(text_words), chunk_size):\n",
        "    # Include overlap from previous chunk\n",
        "    chunk_words = text_words[max(i - overlap_int, 0): i + chunk_size]\n",
        "\n",
        "    # Join words to form chunk\n",
        "    chunk = \" \".join(chunk_words)\n",
        "\n",
        "    chunks.append(chunk)\n",
        "\n",
        "  return chunks"
      ],
      "metadata": {
        "id": "hgm6oXGZVWR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Extract and Process PDFs\n",
        "Extract text and create chunks from each paper"
      ],
      "metadata": {
        "id": "aOLwWWeDaYjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_chunk_pdf(pdf_path, chunk_size=150, overlap=0.2):\n",
        "    \"\"\"Extract text from PDF and return chunks\"\"\"\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        full_text = \"\"\n",
        "\n",
        "        # Extract all pages\n",
        "        for page in reader.pages:\n",
        "            text = page.extract_text()\n",
        "            if text:\n",
        "                full_text += text + \" \"\n",
        "\n",
        "        # Clean text\n",
        "        full_text = re.sub(r'\\s+', ' ', full_text)\n",
        "        full_text = re.sub(r'\\n+', ' ', full_text)\n",
        "\n",
        "        # Create chunks\n",
        "        chunks = get_chunks_fixed_size_with_overlap(full_text, chunk_size, overlap)\n",
        "\n",
        "        return chunks, len(reader.pages), True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        return [], 0, False\n",
        "\n",
        "# Process all PDFs and create dataset\n",
        "PAPERS_DATA = []\n",
        "\n",
        "for pdf_file in pdf_files:\n",
        "    pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "    paper_name = pdf_file.replace('.pdf', '')\n",
        "\n",
        "    # Extract and chunk\n",
        "    chunks, num_pages, success = extract_and_chunk_pdf(pdf_path)\n",
        "\n",
        "    if success:\n",
        "        for i, chunk in enumerate(chunks):\n",
        "\n",
        "            PAPERS_DATA.append({\n",
        "                'content': chunk, # Main text for search\n",
        "                'source': paper_name, # Which paper it's from\n",
        "                'id': f\"{paper_name}_{i}\" # Pos in paper\n",
        "            })\n",
        "    else:\n",
        "        print(f\"  ‚ùå Failed to process\")\n",
        "\n",
        "print(f\"\\n‚úÖ Total chunks created: {len(PAPERS_DATA)}\")"
      ],
      "metadata": {
        "id": "uydg2JLDI3K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Implement Retrieval functions\n",
        "Build BM25 (keyword) and Semantic Search capabilities."
      ],
      "metadata": {
        "id": "SW7Y1jyAeM3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create corpus for searching (combining all text for each chunk)\n",
        "corpus = [x['content'] for x in PAPERS_DATA]\n",
        "\n",
        "print(f\"Corpus ready with {len(corpus)} chunks\")\n",
        "print(f\"From {len(set([x['source'] for x in PAPERS_DATA]))} papers\")"
      ],
      "metadata": {
        "id": "Og3OHquYdMaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3.1: BM25 (Keyword) Search\n"
      ],
      "metadata": {
        "id": "PYFDQEDsgWGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create BM25 Retriever\n",
        "BM25_RETRIEVER = bm25s.BM25(corpus=corpus)\n",
        "\n",
        "# Tokenize the corpus\n",
        "TOKENIZED_DATA = bm25s.tokenize(corpus)\n",
        "\n",
        "# Index the tokenized data\n",
        "BM25_RETRIEVER.index(TOKENIZED_DATA)"
      ],
      "metadata": {
        "id": "FAn4vRbKfZZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bm25_retrieve(query: str, top_k: int = 5):\n",
        "  \"\"\"\n",
        "  BM25 retrieval - keyword-based search\n",
        "  \"\"\"\n",
        "\n",
        "  tokenized_query = bm25s.tokenize(query)\n",
        "\n",
        "  # Retrieve documents\n",
        "  results, scores = BM25_RETRIEVER.retrieve(tokenized_query, k=top_k)\n",
        "\n",
        "  # Get indices\n",
        "  results = results[0]\n",
        "  top_k_indices = [corpus.index(result) for result in results]\n",
        "\n",
        "  return top_k_indices\n",
        "\n",
        "# Test BM25\n",
        "test_query = \"pesticide exposure health effects\"\n",
        "bm25_results = bm25_retrieve(test_query, top_k=3)\n",
        "\n",
        "print(f\"Query: {test_query}\")\n",
        "for idx in bm25_results[:3]:\n",
        "  print(f\"\\n Source: {PAPERS_DATA[idx]['source']}\")\n",
        "  print(f\"Preview: {PAPERS_DATA[idx]['content'][:200]}...\")"
      ],
      "metadata": {
        "id": "KaVP8UDvg0Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3.2 : Semantic Search With Embeddings\n",
        "Create embeddings for semantic understanding"
      ],
      "metadata": {
        "id": "7L6kA1EWid9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Initialize the embedding model\n",
        "# Using a model suitable for scientific/health content\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Generate embeddings for all chunks\n",
        "EMBEDDINGS = model.encode(corpus, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "J9snXWjjiOyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Semantic Search Function\n",
        "def semantic_search_retrieve(query, top_k=5):\n",
        "  \"\"\"\n",
        "  Semantic search using embeddings\n",
        "  \"\"\"\n",
        "  query_embedding = model.encode(query)\n",
        "\n",
        "  # Calculate cosine similarity\n",
        "  from sklearn.metrics.pairwise import cosine_similarity\n",
        "  similarities = cosine_similarity([query_embedding], EMBEDDINGS)[0]\n",
        "\n",
        "  # Get top-k indices\n",
        "  top_k_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "\n",
        "  return top_k_indices.tolist()\n",
        "\n",
        "# Test semantic search\n",
        "semantic_results = semantic_search_retrieve(test_query, top_k=3)\n",
        "\n",
        "print(f\"Query: {test_query}\")\n",
        "for idx in semantic_results[:3]:\n",
        "  print(f\"\\n Source: {PAPERS_DATA[idx]['source']}\")\n",
        "  print(f\"Preview: {PAPERS_DATA[idx]['content'][:200]}...\")"
      ],
      "metadata": {
        "id": "5bvxVMmpkZJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3.3: Reciprocal Rank Fusion (RRF)\n",
        "Combine BM25 and Semantic Search using RRF - to reward documents/papers that rank higher in each retrieval technique list."
      ],
      "metadata": {
        "id": "1iyWzifJmMb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RRF Example\n",
        "# RRF function (exactly from the example)\n",
        "def reciprocal_rank_fusion(list1, list2, top_k=5, K=60):\n",
        "    \"\"\"\n",
        "    Combine results from BM25 and Semantic Search\n",
        "    \"\"\"\n",
        "    rrf_scores = {}\n",
        "\n",
        "    # Calculate RRF scores\n",
        "    for lst in [list1, list2]:\n",
        "        for rank, item in enumerate(lst, start=1):\n",
        "            if item not in rrf_scores:\n",
        "                rrf_scores[item] = 0\n",
        "            rrf_scores[item] += 1 / (rank + K)\n",
        "\n",
        "    # Sort by score\n",
        "    sorted_items = sorted(rrf_scores, key=rrf_scores.get, reverse=True)\n",
        "\n",
        "    return sorted_items[:top_k]\n",
        "\n",
        "# Test RRF\n",
        "bm25_list = bm25_retrieve(test_query, top_k=5)\n",
        "semantic_list = semantic_search_retrieve(test_query, top_k=5)\n",
        "rrf_list = reciprocal_rank_fusion(bm25_list, semantic_list, top_k=5)\n",
        "\n",
        "print(\"üîÄ Reciprocal Rank Fusion Results:\")\n",
        "print(f\"BM25 returned: {bm25_list}\")\n",
        "print(f\"Semantic returned: {semantic_list}\")\n",
        "print(f\"RRF combined: {rrf_list}\")"
      ],
      "metadata": {
        "id": "64YCpQeGmjkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sV3nQ5SMm1tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_papers(indices):\n",
        "  \"\"\"\n",
        "  Retrieve paper chunks by indices\n",
        "  \"\"\"\n",
        "  return [PAPERS_DATA[index] for index in indices]\n",
        "\n",
        "retrieved_papers = query_papers(rrf_list[:3])\n",
        "for i, paper in enumerate(retrieved_papers, 1):\n",
        "  print(f\"\\n{i}. Source: {paper['source']}\")\n",
        "  print(f\"  Content: {paper['content'][:200]}...\")"
      ],
      "metadata": {
        "id": "2Yh7AZMNnDa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interactive Query Interface"
      ],
      "metadata": {
        "id": "xrWE-lnJZ4Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the generate function from utils (or define a simple one for testing)\n",
        "def generate_with_single_input(prompt, **kwargs):\n",
        "    \"\"\"\n",
        "    Placeholder for LLM generation\n",
        "    In production, this would call your LLM API\n",
        "    For now, returns a formatted response with the context\n",
        "    \"\"\"\n",
        "    return {\n",
        "        'content': f\"Based on the retrieved information:\\n\\n{prompt[:500]}...\\n\\n[This would be the LLM's complete response]\"\n",
        "    }\n",
        "\n",
        "# Function to create the final prompt (from the example)\n",
        "def generate_final_prompt(query, top_k, retrieve_function=None, use_rag=True):\n",
        "    \"\"\"\n",
        "    Generate prompt with retrieved context\n",
        "    Based on the Coursera example\n",
        "    \"\"\"\n",
        "    if not use_rag:\n",
        "        return query\n",
        "\n",
        "    # Handle RRF specially\n",
        "    if retrieve_function.__name__ == 'reciprocal_rank_fusion':\n",
        "        list1 = semantic_search_retrieve(query, top_k)\n",
        "        list2 = bm25_retrieve(query, top_k)\n",
        "        top_k_indices = retrieve_function(list1, list2, top_k)\n",
        "    else:\n",
        "        top_k_indices = retrieve_function(query=query, top_k=top_k)\n",
        "\n",
        "    # Get the actual paper chunks\n",
        "    relevant_chunks = query_papers(top_k_indices)\n",
        "\n",
        "    # Format the context\n",
        "    context_parts = []\n",
        "    for chunk in relevant_chunks:\n",
        "        context_parts.append(f\"Source: {chunk['source']}\\n{chunk['content'][:300]}...\")\n",
        "\n",
        "    context = \"\\n\\n\".join(context_parts)\n",
        "\n",
        "    # Create the prompt\n",
        "    prompt = f\"\"\"Answer the user query based on the following scientific paper excerpts about farmworker health.\n",
        "\n",
        "Context from papers:\n",
        "{context}\n",
        "\n",
        "Query: {query}\n",
        "\n",
        "Please provide a comprehensive answer based on the above context:\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# Main LLM call function\n",
        "def llm_call(query, retrieve_function=None, top_k=5, use_rag=True):\n",
        "    \"\"\"\n",
        "    Call LLM with or without RAG\n",
        "    \"\"\"\n",
        "    prompt = generate_final_prompt(query, top_k=top_k, retrieve_function=retrieve_function, use_rag=use_rag)\n",
        "    generated_response = generate_with_single_input(prompt)\n",
        "    return generated_response['content']"
      ],
      "metadata": {
        "id": "acKORWZoZ7IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Display Widget"
      ],
      "metadata": {
        "id": "OF257LgSaEV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def display_widget(llm_call_func, semantic_search_retrieve, bm25_retrieve, reciprocal_rank_fusion):\n",
        "    \"\"\"\n",
        "    Create interactive widget for comparing retrieval methods\n",
        "    Exactly from the Coursera example\n",
        "    \"\"\"\n",
        "    def on_button_click(b):\n",
        "        query = query_input.value\n",
        "        top_k = slider.value\n",
        "\n",
        "        # Clear existing outputs\n",
        "        for output in [output1, output2, output3, output4]:\n",
        "            output.clear_output()\n",
        "        status_output.clear_output()\n",
        "\n",
        "        # Display \"Generating...\" message\n",
        "        with status_output:\n",
        "            print(\"Generating responses...\")\n",
        "\n",
        "        # Update outputs one by one\n",
        "        results = [\n",
        "            (output1, llm_call_func, query, True, top_k, semantic_search_retrieve),\n",
        "            (output2, llm_call_func, query, True, top_k, bm25_retrieve),\n",
        "            (output3, llm_call_func, query, True, top_k, reciprocal_rank_fusion),\n",
        "            (output4, llm_call_func, query, False, top_k, None)\n",
        "        ]\n",
        "\n",
        "        for output, func, query, use_rag, top_k, retriever in results:\n",
        "            response = func(query=query, use_rag=use_rag, top_k=top_k, retrieve_function=retriever)\n",
        "            with output:\n",
        "                display(Markdown(response))\n",
        "\n",
        "        # Clear \"Generating...\" message\n",
        "        status_output.clear_output()\n",
        "        with status_output:\n",
        "            print(\"‚úÖ Results ready!\")\n",
        "\n",
        "    # Create UI elements\n",
        "    query_input = widgets.Text(\n",
        "        description='',\n",
        "        placeholder='Enter your query about farmworker health...',\n",
        "        layout=widgets.Layout(width='100%')\n",
        "    )\n",
        "\n",
        "    slider = widgets.IntSlider(\n",
        "        value=5,\n",
        "        min=1,\n",
        "        max=20,\n",
        "        step=1,\n",
        "        description='Top K:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    # Output areas with styling\n",
        "    output_style = {'border': '1px solid #ccc', 'width': '100%'}\n",
        "    output1 = widgets.Output(layout=output_style)\n",
        "    output2 = widgets.Output(layout=output_style)\n",
        "    output3 = widgets.Output(layout=output_style)\n",
        "    output4 = widgets.Output(layout=output_style)\n",
        "    status_output = widgets.Output()\n",
        "\n",
        "    submit_button = widgets.Button(\n",
        "        description=\"Get Responses\",\n",
        "        button_type='primary',\n",
        "        style={'button_color': '#4CAF50'}\n",
        "    )\n",
        "    submit_button.on_click(on_button_click)\n",
        "\n",
        "    # Labels for each method\n",
        "    label1 = widgets.Label(value=\"üß† Semantic Search\")\n",
        "    label2 = widgets.Label(value=\"üî§ BM25 Search\")\n",
        "    label3 = widgets.Label(value=\"üîÄ Reciprocal Rank Fusion\")\n",
        "    label4 = widgets.Label(value=\"‚ùå Without RAG\")\n",
        "\n",
        "    # Display the interface\n",
        "    display(widgets.HTML(\"\"\"\n",
        "    <h2>üîç Farmworker Health Research Query System</h2>\n",
        "    <p>Compare different retrieval methods for your research questions</p>\n",
        "    \"\"\"))\n",
        "\n",
        "    display(query_input, slider, submit_button, status_output)\n",
        "\n",
        "    # Create layout with 2x2 grid\n",
        "    vbox1 = widgets.VBox([label1, output1], layout={'width': '48%'})\n",
        "    vbox2 = widgets.VBox([label2, output2], layout={'width': '48%'})\n",
        "    vbox3 = widgets.VBox([label3, output3], layout={'width': '48%'})\n",
        "    vbox4 = widgets.VBox([label4, output4], layout={'width': '48%'})\n",
        "\n",
        "    hbox_outputs1 = widgets.HBox([vbox1, vbox2], layout={'justify_content': 'space-between'})\n",
        "    hbox_outputs2 = widgets.HBox([vbox3, vbox4], layout={'justify_content': 'space-between'})\n",
        "\n",
        "    # Style the outputs\n",
        "    def style_outputs(*outputs):\n",
        "        for output in outputs:\n",
        "            output.layout.margin = '5px'\n",
        "            output.layout.height = '300px'\n",
        "            output.layout.padding = '10px'\n",
        "            output.layout.overflow = 'auto'\n",
        "\n",
        "    style_outputs(output1, output2, output3, output4)\n",
        "\n",
        "    # Display the grid\n",
        "    display(hbox_outputs1)\n",
        "    display(hbox_outputs2)\n",
        "\n",
        "# Launch the widget!\n",
        "print(\"üöÄ Launching Interactive Query Interface...\")\n",
        "display_widget(llm_call, semantic_search_retrieve, bm25_retrieve, reciprocal_rank_fusion)"
      ],
      "metadata": {
        "id": "EQCGl7pMoZNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WwvvR0v0aXMC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}